{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 - graphing\n",
    "\n",
    "In this notebook I aim to use prepared data in order to create train and test graphs and dataloader functions for further use in the models training and testing.\n",
    "\n",
    "## Bayesian Personalized Ranking (BPR)\n",
    "\n",
    "There is such concept BRP which we will highly use in this work. Simply, for a set of given users we would aggregate \"positive\" items which really exist and \"negative\" items which are not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id_idx</th>\n",
       "      <th>item_id_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>887080905</td>\n",
       "      <td>575</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>891464148</td>\n",
       "      <td>829</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>879456334</td>\n",
       "      <td>526</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>879376967</td>\n",
       "      <td>869</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>879442377</td>\n",
       "      <td>803</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  timestamp  user_id_idx  item_id_idx\n",
       "0       3  887080905          575          275\n",
       "1       4  891464148          829          691\n",
       "2       5  879456334          526          179\n",
       "3       4  879376967          869            9\n",
       "4       4  879442377          803          654"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# load train dataframe for example\n",
    "train = pd.read_csv(\"../data/interim/train.csv\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(df: pd.DataFrame, batch_size: int = 32):\n",
    "    \"\"\"\n",
    "    dataloader uses BRP idea to create batches of data\n",
    "    \"\"\"\n",
    "\n",
    "    n_users = df.user_id_idx.nunique()\n",
    "\n",
    "    # sample 'batch_size' users\n",
    "    users = np.random.choice(n_users, size=batch_size, replace=False)\n",
    "    # sort users\n",
    "    users.sort()\n",
    "\n",
    "    # helper function to sample from dataframe group\n",
    "    def sample(group):\n",
    "        return group.sample(1)\n",
    "\n",
    "    # sample by one existing item for each user\n",
    "    items = (\n",
    "        df[df.user_id_idx.isin(users)].groupby(\"user_id_idx\").apply(sample).item_id_idx\n",
    "    )\n",
    "\n",
    "    # create temporary table where there will be all user-item non-existing pairs\n",
    "    df_outside_batch = df[~df.user_id_idx.isin(users)]\n",
    "\n",
    "    non_items = (\n",
    "        df_outside_batch.groupby(\"user_id_idx\")\n",
    "        .apply(lambda x: np.random.choice(x.item_id_idx))\n",
    "        .sample(batch_size)\n",
    "    )\n",
    "\n",
    "    # for each item we have to add the number of users so that the index will be unique among users\n",
    "    items = items + n_users\n",
    "    non_items = non_items + n_users\n",
    "\n",
    "    # return tensors\n",
    "    return (\n",
    "        torch.Tensor(list(users)).long(),\n",
    "        torch.Tensor(list(items)).long(),\n",
    "        torch.Tensor(list(non_items)).long(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([311, 463, 901]),\n",
       " tensor([1908, 1690, 1069]),\n",
       " tensor([1488, 1032, 1886]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = dataloader(train, batch_size=3)\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether our logic was correct\n",
    "\n",
    "users = batch[0].numpy()\n",
    "items = batch[1].numpy()\n",
    "non_items = batch[2].numpy()\n",
    "\n",
    "n_users = train.user_id_idx.nunique()\n",
    "\n",
    "entry = train[\n",
    "    (train.user_id_idx == users[0]) & (train.item_id_idx == items[0] - n_users)\n",
    "]\n",
    "\n",
    "assert entry.shape[0] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that there is not edge with first user and non-existing corresponding item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = train[\n",
    "    (train.user_id_idx == users[0]) & (train.item_id_idx == non_items[0] - n_users)\n",
    "]\n",
    "\n",
    "assert entry.shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses:\n",
    "\n",
    "As we use BRP, definition of its loss implementation can be found [here](https://d2l.ai/chapter_recommender-systems/ranking.html). I will combine both approaches from the website and from [this work](https://medium.com/stanford-cs224w/recommender-systems-with-gnns-in-pyg-d8301178e377)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(users, users_emb, pos_emb, neg_emb, user_emb0, pos_emb0, neg_emb0):\n",
    "    # compute loss from initial embeddings, used for regulization\n",
    "    reg_loss = (\n",
    "        (1 / 2)\n",
    "        * (user_emb0.norm().pow(2) + pos_emb0.norm().pow(2) + neg_emb0.norm().pow(2))\n",
    "        / float(len(users))\n",
    "    )\n",
    "\n",
    "    # compute BPR loss from user, positive item, and negative item embeddings\n",
    "    pos_scores = torch.mul(users_emb, pos_emb).sum(dim=1)\n",
    "    neg_scores = torch.mul(users_emb, neg_emb).sum(dim=1)\n",
    "\n",
    "    bpr_loss = torch.mean(F.softplus(neg_scores - pos_scores))\n",
    "\n",
    "    brp_loss2 = torch.sum(torch.log(torch.sigmoid(pos_scores - neg_scores)))\n",
    "\n",
    "    return brp_loss2, reg_loss\n",
    "\n",
    "    return bpr_loss, reg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "For the metrics I will use precision and recall because they are the most common. Moreover, as the work I base on uses them, I will use them too.\n",
    "\n",
    "- Precision - is the fraction of relevant instances among the retrieved instances\n",
    "- Recall - is the fraction of relevant instances that have been retrieved over the total amount of relevant instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(user_embeddings, item_embeddings, n_users, n_items, traindf, testdf, K):\n",
    "    \"\"\"\n",
    "    Compute precision and recall\n",
    "    \"\"\"\n",
    "\n",
    "    relevance = torch.mm(user_embeddings, item_embeddings.t())\n",
    "\n",
    "    # dense tensor of all user-item interactions\n",
    "    i = torch.LongTensor([traindf.user_id_idx, traindf.item_id_idx])\n",
    "    v = torch.FloatTensor([1] * traindf.shape[0])\n",
    "    train_interactions = torch.sparse.FloatTensor(i, v, torch.Size([n_users, n_items]))\n",
    "\n",
    "    # mask user-item pairs from metric computation\n",
    "    relevance_score = torch.mul(relevance, (1 - train_interactions.to_dense()))\n",
    "\n",
    "    # get top K items for each user\n",
    "    _, topk_idx = torch.topk(relevance_score, K)\n",
    "\n",
    "    # measure overlap between recommended (top-scoring) and held-out user-item interactions\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmldl-recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
